{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프롬프트 템플릿 : 언어 모델에 대한 프롬프트를 생성하기 위한 미리 정의된 레시피\n",
    "- 지침, 예시, 특정 맥락 및 주어진 작업에 적합한 질문 포함될 수 있음.\n",
    "- langchain은 다양한 언어 모델에서 쉽게 재사용될 수 있도록 모델에 독립적인 템플릿을 만듦\n",
    "- 언어모델의 프롬프트 형태 : 문자열 또는 채팅 메시지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[PromptTemplate]\n",
    ":문자열 프롬프트에 대한 템플릿 만듦\n",
    "- 여러개의 변수를 둘 수도 있고, 변수가 없을 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate # type: ignore\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke\")\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ChatPromptTemplate]\n",
    ": chat model에게 주는 prompt로 챗메시지의 목록이다.\n",
    "- 챗메시지 : role 매개변수와 내용으로 구성됨\n",
    "- role(OpenAI Chat Completion API에서는) :  AI, human, system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot. your name is Bob.'),\n",
       " HumanMessage(content='humanHello, how are you doing?'),\n",
       " AIMessage(content=\"I'm donig well, thanks!\"),\n",
       " HumanMessage(content='what is your name?')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate # type: ignore\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful AI bot. your name is {name}.\"),\n",
    "        (\"human\" \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm donig well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"what is your name?\" )\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- 형식화된 메시지를 langchain의 chat model 클래스(ChatOpenAI)에 piping하는 것은 OpenAI client를 직접 사용하는 것과 거의 같다. # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from aiohttp->openai) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\desktop\\langchain\\env\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAI(model_name='gpt-3.5-turbo', model='gpt-3.5-turbo', messages=[{'role': 'system', 'content': 'You are a helpful AI bot. your name is Bob.'}, {'role': 'human', 'content': 'Hello, how are you doing?'}, {'role': 'assistant', 'content': \"I'm donig well, thanks!\"}, {'role': 'human', 'content': 'What is your name'}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms.openai import OpenAI # type: ignore\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.construct(\n",
    "    model =\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\",\"content\":\"You are a helpful AI bot. your name is Bob.\"},\n",
    "        {\"role\":\"human\",\"content\":\"Hello, how are you doing?\"},\n",
    "        {\"role\":\"assistant\", \"content\":\"I'm donig well, thanks!\"},\n",
    "        {\"role\":\"human\", \"content\":\"What is your name\"},\n",
    "    ],\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ChatPromptTemplat.from_messages()는 MessagePromptTemplate나 BaseMessage의 인스턴스를 전달할 수 있음.\n",
    "- MessagePromptTemplat : AIMessagePromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "- ChatMessagePromptTemplate : 임의의 역할을 부여하고 싶을 때 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that re-wrihe the user's text to sound more upbeat.\"),\n",
       " HumanMessage(content=\"I don't like eating tasty things\")]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import SystemMessagePromptTemplate, HumanMessagePromptTemplate, SystemMessage # type: ignore\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a helpful assistant that re-wrihe the user's text to sound more upbeat.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(text=\"I don't like eating tasty things\")\n",
    "\n",
    "messages\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatMessage(content='May the force be with you', role='Jedi')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import ChatMessagePromptTemplate # type: ignore\n",
    "\n",
    "prompt = \"May the {subject} be with you\"\n",
    "\n",
    "chat_message_prompt = ChatMessagePromptTemplate.from_template(\n",
    "    role=\"Jedi\", template=prompt\n",
    ")\n",
    "\n",
    "chat_message_prompt.format(subject=\"force\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MessagesPlaceHolder] :\n",
    "- 포맷팅 중에 랜더링할 메시지를 제어할 수 있음.\n",
    "- 메시지 프롬프트 템플릿에 어떤 role을 사용할지 확실하지 않거나, 포매팅 중 메시지 목록을 삽입하려는 경우 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': typing.List[typing.Union[langchain.schema.messages.AIMessage, langchain.schema.messages.HumanMessage, langchain.schema.messages.ChatMessage, langchain.schema.messages.SystemMessage, langchain.schema.messages.FunctionMessage]]}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], template='Summarize our conversation so far in {word_count} words.')), MessagesPlaceholder(variable_name='conversation')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ( # type: ignore\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "human_prompt = \"Summarize our conversation so far in {word_count} words.\"\n",
    "human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [human_message_template,\n",
    "     MessagesPlaceholder(variable_name=\"conversation\") ]\n",
    ")\n",
    "\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Summarize our conversation so far in 10 words.'),\n",
       " HumanMessage(content='What is the best way to learn programming?'),\n",
       " AIMessage(content='\\n1. Choose a programming language: Decide on a programming language that you want to learn.\\n\\n2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.\\n\\n3. Practice, practice, practice: The best way to learn programming is through hands-on experience\\n')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.messages import AIMessage, HumanMessage # type: ignore\n",
    "\n",
    "human_message = HumanMessage(content=\"What is the best way to learn programming?\")\n",
    "\n",
    "ai_message = AIMessage(\n",
    "    content=\"\"\"\n",
    "1. Choose a programming language: Decide on a programming language that you want to learn.\n",
    "\n",
    "2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.\n",
    "\n",
    "3. Practice, practice, practice: The best way to learn programming is through hands-on experience\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chat_prompt.format_prompt(\n",
    "    conversation=[human_message, ai_message], word_count=\"10\"\n",
    ").to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[LCEL] : LangChain Expression Language\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
