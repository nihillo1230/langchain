{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Winston goes to work at the Ministry of Truth.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 300,\n",
    "    chunk_overlap = 50,\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader('./files/george_orwell.csv')\n",
    "\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs,cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "###  map_reduce chain 의 구현순서\n",
    "# 1. list of docs\n",
    "\n",
    "# 2. for doc in list of docs | prompt | llm\n",
    "\n",
    "# 3. for response in list of llms response | put them all together\n",
    "\n",
    "# 4. final doc | prompt | llm\n",
    "\n",
    "map_doc_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        Use the following portion of a long document to see if any of the text is relevant to answer the question. Return any relevant text verbatim.\n",
    "        -------\n",
    "        {context}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\",\"{question}\")\n",
    "])\n",
    "\n",
    "map_doc_chain = map_doc_prompt | llm\n",
    "\n",
    "# def map_docs(inputs):\n",
    "#     # print(inputs)\n",
    "#     documents = inputs[\"documents\"]\n",
    "#     question = inputs[\"question\"]\n",
    "#     results = []\n",
    "#     for document in documents:\n",
    "#         result = map_doc_chain.invoke(\n",
    "#             {\"context\": document.page_content,         \"question\":question}\n",
    "#         ).content\n",
    "#         results.append(result)\n",
    "#     results = \"\\n\\n\".join(results)\n",
    "#     # print(results)\n",
    "#     return results\n",
    "\n",
    "def map_docs(inputs):\n",
    "    documents = inputs[\"documents\"]\n",
    "    question = inputs[\"question\"]\n",
    "    return \"\\n\\n\".join(\n",
    "        map_doc_chain.invoke(\n",
    "            {\"context\":doc.page_content,     \"question\":question}\n",
    "        ).content \n",
    "        for doc in documents\n",
    "    )\n",
    "    \n",
    "\n",
    "map_chain = {\n",
    "    \"documents\":retriever,\n",
    "    \"question\":RunnablePassthrough(),\n",
    "} | RunnableLambda(map_docs)\n",
    "\n",
    "# {\n",
    "#     \"documents\": [Documents],\n",
    "#     \"question\":\"Describe Victory Mansions?\"\n",
    "# }\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\n",
    "        \"system\",\n",
    "        \"\"\"\n",
    "        Given the following extracted parts of a long document and a question, create a final answer.\n",
    "        if you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
    "        ------------\n",
    "        {context}\n",
    "        \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "chain = {\n",
    "    \"context\": map_chain, \n",
    "    \"question\":RunnablePassthrough(),\n",
    "} | final_prompt | llm\n",
    "\n",
    "chain.invoke(\"Where does Winston go to work?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
